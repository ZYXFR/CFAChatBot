{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import (\n",
    "  AutoTokenizer, \n",
    "  AutoModelForCausalLM, \n",
    "  BitsAndBytesConfig,\n",
    "  pipeline)\n",
    "import transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.document_transformers import Html2TextTransformer\n",
    "from langchain.document_loaders import AsyncChromiumLoader\n",
    "\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores.faiss import FAISS\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "import nest_asyncio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#################################################################\n",
    "# Tokenizer\n",
    "\n",
    "#################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 本地模型路径\n",
    "local_model_path = \"/disk2/elvys/Mistral-7B-Instruct-v0.2\"\n",
    "model_config = transformers.AutoConfig.from_pretrained(\n",
    "    local_model_path,\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(local_model_path, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Your GPU supports bfloat16: accelerate training with bf16=True\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "#################################################################\n",
    "# bitsandbytes parameters\n",
    "#################################################################\n",
    "\n",
    "# Activate 4-bit precision base model loading\n",
    "use_4bit = True\n",
    "\n",
    "# Compute dtype for 4-bit base models\n",
    "bnb_4bit_compute_dtype = \"float16\"\n",
    "\n",
    "# Quantization type (fp4 or nf4)\n",
    "bnb_4bit_quant_type = \"nf4\"\n",
    "\n",
    "# Activate nested quantization for 4-bit base models (double quantization)\n",
    "use_nested_quant = False\n",
    "\n",
    "#################################################################\n",
    "# Set up quantization config\n",
    "#################################################################\n",
    "compute_dtype = getattr(torch, bnb_4bit_compute_dtype)\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=use_4bit,\n",
    "    bnb_4bit_quant_type=bnb_4bit_quant_type,\n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    "    bnb_4bit_use_double_quant=use_nested_quant,\n",
    ")\n",
    "\n",
    "# Check GPU compatibility with bfloat16\n",
    "if compute_dtype == torch.float16 and use_4bit:\n",
    "    major, _ = torch.cuda.get_device_capability()\n",
    "    if major >= 8:\n",
    "        print(\"=\" * 80)\n",
    "        print(\"Your GPU supports bfloat16: accelerate training with bf16=True\")\n",
    "        print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 6/6 [00:07<00:00,  1.20s/it]\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    local_model_path,\n",
    "    torch_dtype=torch.float16,\n",
    "    attn_implementation=\"flash_attention_2\",\n",
    "    device_map=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable model parameters: 7241732096\n",
      "all model parameters: 7241732096\n",
      "percentage of trainable model parameters: 100.00%\n"
     ]
    }
   ],
   "source": [
    "def print_number_of_trainable_model_parameters(model):\n",
    "    trainable_model_params = 0\n",
    "    all_model_params = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_model_params += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_model_params += param.numel()\n",
    "    return f\"trainable model parameters: {trainable_model_params}\\nall model parameters: {all_model_params}\\npercentage of trainable model parameters: {100 * trainable_model_params / all_model_params:.2f}%\"\n",
    "\n",
    "print(print_number_of_trainable_model_parameters(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_generation_pipeline = pipeline(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    task=\"text-generation\",\n",
    "    temperature=0.2,\n",
    "    repetition_penalty=1.1,\n",
    "    return_full_text=True,\n",
    "    max_new_tokens=1000,\n",
    ")\n",
    "\n",
    "mistral_llm = HuggingFacePipeline(pipeline=text_generation_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs: tensor([[    1,   733, 16289, 28793, 28705,    13, 27014,   334,  3120,   349,\n",
      "           430,   820,   433,   349, 12302, 28792, 28748, 16289, 28793]],\n",
      "       device='cuda:0')\n",
      "Attention Mask: tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[INST] \\nwhy CFA is programe is valuable[/INST] The Chartered Financial Analyst (CFA) program is considered valuable for several reasons:\\n\\n1. Global Recognition: The CFA designation is recognized and respected by employers around the world. It demonstrates a high level of knowledge and expertise in the field of investment management and financial analysis.\\n2. Comprehensive Curriculum: The CFA program covers a broad range of topics in finance, including ethical and professional standards, financial analysis, portfolio management, economics, and behavioral finance.\\n3. Practical Skills: The CFA program emphasizes practical skills and real-world applications of financial concepts. Candidates are required to pass three levels of exams, each of which tests their ability to apply financial theory to real-world situations.\\n4. Networking Opportunities: The CFA Institute and local CFA societies offer numerous networking opportunities for CFA charterholders. These networks can provide valuable connections and resources for career advancement and professional development.\\n5. Ethical Standards: The CFA program places a strong emphasis on ethical and professional standards. Candidates are required to adhere to a strict code of ethics and professional conduct, which can help build trust and credibility with clients and employers.\\n6. Career Advancement: The CFA designation can be a valuable asset for career advancement in the finance industry. Many employers prefer to hire or promote candidates who have earned the CFA designation, as it demonstrates a commitment to ongoing professional development and a deep understanding of financial concepts.\\n7. Versatility: The skills and knowledge gained through the CFA program are applicable to a wide range of careers in finance, including investment analysis, portfolio management, financial planning, and risk management. This versatility can make CFA charterholders attractive to employers in various industries and sectors.']\n"
     ]
    }
   ],
   "source": [
    "# 编码输入并生成注意力掩码\n",
    "inputs_not_chat = tokenizer.encode_plus(\"\"\"[INST] \n",
    "why CFA is programe is valuable[/INST]\"\"\"\n",
    "                                        , return_tensors=\"pt\", padding=True)\n",
    "\n",
    "# 将输入张量移动到GPU\n",
    "input_ids = inputs_not_chat['input_ids'].to('cuda')\n",
    "attention_mask = inputs_not_chat['attention_mask'].to('cuda')\n",
    "\n",
    "# 输出检查\n",
    "print(\"Input IDs:\", input_ids)\n",
    "print(\"Attention Mask:\", attention_mask)\n",
    "\n",
    "# 调整生成参数并设置 torch.no_grad()\n",
    "try:\n",
    "    with torch.no_grad():\n",
    "        generated_ids = model.generate(\n",
    "            input_ids, \n",
    "            attention_mask=attention_mask, \n",
    "            max_new_tokens=1000, \n",
    "            do_sample=True,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            temperature=0.5,  # 调整temperature参数\n",
    "        )\n",
    "    decoded = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "    print(decoded)\n",
    "except RuntimeError as e:\n",
    "    print(f\"An error occurred during generation: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "File path /home/yzhao/projects/RD/LangChain/document/A Complete Guide to the Futures Market Technical Analysis, Trading Systems, Fundamental Analysis, Options, Spreads, and... (Jack D. Schwager) (Z-Library).pdf is not a valid file or url",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocument_loaders\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PyPDFLoader\n\u001b[1;32m      2\u001b[0m loaders \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# Duplicate documents on purpose - messy data\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m     \u001b[43mPyPDFLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/home/yzhao/projects/RD/LangChain/document/A Complete Guide to the Futures Market Technical Analysis, Trading Systems, Fundamental Analysis, Options, Spreads, and... (Jack D. Schwager) (Z-Library).pdf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m,\n\u001b[1;32m      5\u001b[0m ]\n\u001b[1;32m      6\u001b[0m loader \u001b[38;5;241m=\u001b[39m loaders[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      7\u001b[0m pages \u001b[38;5;241m=\u001b[39m loader\u001b[38;5;241m.\u001b[39mload_and_split()\n",
      "File \u001b[0;32m~/anaconda3/envs/LLM/lib/python3.12/site-packages/langchain_community/document_loaders/pdf.py:182\u001b[0m, in \u001b[0;36mPyPDFLoader.__init__\u001b[0;34m(self, file_path, password, headers, extract_images)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m    180\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpypdf package not found, please install it with \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`pip install pypdf`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    181\u001b[0m     )\n\u001b[0;32m--> 182\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparser \u001b[38;5;241m=\u001b[39m PyPDFParser(password\u001b[38;5;241m=\u001b[39mpassword, extract_images\u001b[38;5;241m=\u001b[39mextract_images)\n",
      "File \u001b[0;32m~/anaconda3/envs/LLM/lib/python3.12/site-packages/langchain_community/document_loaders/pdf.py:116\u001b[0m, in \u001b[0;36mBasePDFLoader.__init__\u001b[0;34m(self, file_path, headers)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(temp_pdf)\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_path):\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile path \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not a valid file or url\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_path)\n",
      "\u001b[0;31mValueError\u001b[0m: File path /home/yzhao/projects/RD/LangChain/document/A Complete Guide to the Futures Market Technical Analysis, Trading Systems, Fundamental Analysis, Options, Spreads, and... (Jack D. Schwager) (Z-Library).pdf is not a valid file or url"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "loaders = [\n",
    "    # Duplicate documents on purpose - messy data\n",
    "    PyPDFLoader(\"/home/yzhao/projects/RD/LLM/document/Trading Classic Chart Patterns.pdf\"),\n",
    "]\n",
    "loader = loaders[0]\n",
    "pages = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mistral_llm = HuggingFacePipeline(pipeline=text_generation_pipeline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loaders' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 7\u001b[0m\n\u001b[1;32m      2\u001b[0m text_splitter \u001b[38;5;241m=\u001b[39m RecursiveCharacterTextSplitter(\n\u001b[1;32m      3\u001b[0m     chunk_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1500\u001b[39m,\n\u001b[1;32m      4\u001b[0m     chunk_overlap \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m150\u001b[39m\n\u001b[1;32m      5\u001b[0m )\n\u001b[1;32m      6\u001b[0m docs \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m loader \u001b[38;5;129;01min\u001b[39;00m \u001b[43mloaders\u001b[49m:\n\u001b[1;32m      8\u001b[0m     docs\u001b[38;5;241m.\u001b[39mextend(loader\u001b[38;5;241m.\u001b[39mload())\n\u001b[1;32m      9\u001b[0m chunked_documents \u001b[38;5;241m=\u001b[39m text_splitter\u001b[38;5;241m.\u001b[39msplit_documents(docs)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'loaders' is not defined"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1500,\n",
    "    chunk_overlap = 150\n",
    ")\n",
    "docs = []\n",
    "for loader in loaders:\n",
    "    docs.extend(loader.load())\n",
    "chunked_documents = text_splitter.split_documents(docs)\n",
    "len(chunked_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'chunked_documents' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load chunked documents into the FAISS index\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m db \u001b[38;5;241m=\u001b[39m FAISS\u001b[38;5;241m.\u001b[39mfrom_documents(\u001b[43mchunked_documents\u001b[49m, \n\u001b[1;32m      3\u001b[0m                           HuggingFaceEmbeddings(model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentence-transformers/all-mpnet-base-v2\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m      5\u001b[0m retriever \u001b[38;5;241m=\u001b[39m db\u001b[38;5;241m.\u001b[39mas_retriever()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'chunked_documents' is not defined"
     ]
    }
   ],
   "source": [
    "# Load chunked documents into the FAISS index\n",
    "db = FAISS.from_documents(chunked_documents, \n",
    "                          HuggingFaceEmbeddings(model_name='sentence-transformers/all-mpnet-base-v2'))\n",
    "\n",
    "retriever = db.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yzhao/anaconda3/envs/LLM/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### [INST] Instruction: You are a technical analyst.If the problem is not related to the Finance aera, just print 'this is not my aera',otherwise answer the question based on your technical indicator problem. Here is context to help:\n",
      "\n",
      "[Document(page_content='convergence-divergence (MACD), the price (or moving average) oscillator, the commodity chan-\\nnel index (CCI), and the money flow index (MFI). (Note: There is little consistency in the technical indicator lexicon, especially with regard to more generic indicators. T erms such as momentum, rate of change, and price oscillator sometimes refer to different calculations in different sources. The names used here are widely applied, but may conflict with other sources. The calculations, not the names, are what are important.)\\nFigure 11.6 compares five popular indicators: momentum, the “fast” stochastic oscillator, CCI,', metadata={'source': '/home/yzhao/projects/RD/LangChain/document/A Complete Guide to the Futures Market Technical Analysis, Trading Systems, Fundamental Analysis, Options, Spreads, and... (Jack D. Schwager) (Z-Library).pdf', 'page': 180}), Document(page_content='Figure 11.6 compares five popular indicators: momentum, the “fast” stochastic oscillator, CCI, \\nRSI, and the MFI. “Momentum” is simply the Close – Close indicator. The fast stochastic is a three-day moving average of the CS indicator. (The second, thinner line in the stochastic plot in Figure 11.6 is a three-day moving average of the primary indicator line.) The CCI divides the difference between price and a moving average (similar to the Close – MA indicator) by a measure of the absolute total price deviation during the look-back period. The RSI is essentially the U/D Average indicator, except it uses an exponential smoothing function instead of a simple moving average and is scaled from zero to 100 instead of zero to 1. The MFI is basically a volume-weighted version of the RSI that magnifies indicator readings that are accompanied by high trade volume. The precise formulas for these indica-tors (which are readily available online) are less important than the fact that they are all derived from  \\nour basic indicator calculations and are all highly correlated to each other. Table 11.4 summarizes  \\nthe average correlations for 20-day versions of the 10 pair combinations of these five common indica-tors for the same periods shown in Tables 11.2 and 11.3. As Table 11.4 clearly demonstrates, these five popular indicators are all highly correlated, with correlations ranging from a low of 0.67 to a high of 0.94.', metadata={'source': '/home/yzhao/projects/RD/LangChain/document/A Complete Guide to the Futures Market Technical Analysis, Trading Systems, Fundamental Analysis, Options, Spreads, and... (Jack D. Schwager) (Z-Library).pdf', 'page': 180}), Document(page_content='Preli MinariesPart I', metadata={'source': '/home/yzhao/projects/RD/LangChain/document/A Complete Guide to the Futures Market Technical Analysis, Trading Systems, Fundamental Analysis, Options, Spreads, and... (Jack D. Schwager) (Z-Library).pdf', 'page': 18}), Document(page_content='liquidation signals in the latter half of the chart (mid-April 2015 forward), the signals before that \\n    FIGURE  \\xa014.12    relative Strength index in Trend and Trading range Conditions: U.S. dollar index \\nContinuous Futures\\nChart created using TradeStation. ©TradeStation T echnologies, inc. All rights reserved. \\n 1  The rSi was originally introduced in j. Welles Wilder, jr.,  New Concepts in T echnical Trading Systems  (Winston-\\nSalem, NC: Hunter Publishing, 1978).', metadata={'source': '/home/yzhao/projects/RD/LangChain/document/A Complete Guide to the Futures Market Technical Analysis, Trading Systems, Fundamental Analysis, Options, Spreads, and... (Jack D. Schwager) (Z-Library).pdf', 'page': 215})]\n",
      "\n",
      "### QUESTION:\n",
      "what is CCI [/INST]\n",
      "  The Commodity Channel Index (CCI) is a technical indicator that measures the current price level relative to a typical price level over a specified time period. It is calculated by taking the difference between the current price and a moving average, and then dividing that value by a measure of the average deviation of the price from the moving average over the specified time period. This results in a value that can be used to identify potential buy or sell signals when the CCI falls below a certain threshold or crosses above a certain level. The CCI is similar to other momentum indicators like the Relative Strength Index (RSI) and the Moving Average Convergence Divergence (MACD) indicator.\n"
     ]
    }
   ],
   "source": [
    "# Create prompt template,此处可以进行promt engineering\n",
    "prompt_template = \"\"\"\n",
    "### [INST] Instruction: You are a technical analyst.If the problem is not related to the Finance aera, just print 'this is not my aera',otherwise answer the question based on your technical indicator problem. Here is context to help:\n",
    "\n",
    "{context}\n",
    "\n",
    "### QUESTION:\n",
    "{question} [/INST]\n",
    " \"\"\"\n",
    "\n",
    "# Create prompt from prompt template \n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=prompt_template,\n",
    ")\n",
    "\n",
    "# Create llm chain \n",
    "llm_chain = LLMChain(llm=mistral_llm, prompt=prompt)\n",
    "\n",
    "rag_chain = ( \n",
    " {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | llm_chain\n",
    ")\n",
    "\n",
    "print(rag_chain.invoke(\"what is CCI\")['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 关闭模型\n",
    "model.cpu()  # 将模型移到CPU，释放GPU内存\n",
    "del model  # 删除模型对象\n",
    "torch.cuda.empty_cache()  # 清空GPU缓存"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
